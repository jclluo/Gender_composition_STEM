from bs4 import BeautifulSoup
import requests
from urllib.parse import urljoin, urlparse
import pandas as pd

# Website of job market candidates that we want to scrape
url = "https://www.economics.uci.edu/grad/jobmarket.php"

# Get the HTML text from the website
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html.parser')

def get_urls_by_text(soup, text):
    unique_urls = []
    # Find all elements with class "one-third"
    one_third_elements = soup.find_all('div', class_='one-third')
    
    for element in one_third_elements:
        # Check if the element contains the specified text
        if text in element.get_text():
            for link in element.find_all('a', href=True):
                href = link.get('href')
                if href and href not in unique_urls:
                    unique_urls.append(href)
    return unique_urls

# Get the base URL
base_url = "{0.scheme}://{0.netloc}".format(urlparse(url))

# Extract URLs for CVs and Websites from the main page and remove duplicates
cv_link = get_urls_by_text(soup, "CV:")
personal_website = get_urls_by_text(soup, "Website:")

# Create a pandas DataFrame with separate columns for CV links and Website links
df = pd.DataFrame({
    'CV Link': pd.Series(cv_link),
    'Personal Website': pd.Series(personal_website)
})

# Print the DataFrame
print(df)
